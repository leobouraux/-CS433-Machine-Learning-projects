{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from proj1_helpers import *\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction format de tx et y\n",
    "tx = np.c_[np.ones((y.shape[0], 1)), tX]\n",
    "yp = np.expand_dims(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param√®tres\n",
    "gamma = 0.01\n",
    "lambda_ = 0.01\n",
    "max_iters = 10\n",
    "w = np.zeros(tX.shape[1])\n",
    "wp = np.zeros((tX.shape[1], 1))\n",
    "x, mean_x, std_x = standardize(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/9): loss=7107.214138532167, w=[-8.28810705e+03 -2.07227676e+09]\n",
      "Gradient Descent(1/9): loss=100602973466764.31, w=[3.63014661e+08 2.26894524e+19]\n",
      "Gradient Descent(2/9): loss=1.4422318853493344e+24, w=[-2.04883146e+13 -3.20146933e+29]\n",
      "Gradient Descent(3/9): loss=2.0676657531615477e+34, w=[1.17368942e+18 4.58504442e+39]\n",
      "Gradient Descent(4/9): loss=2.9643243292103956e+44, w=[-6.73002579e+22 -6.57286392e+49]\n",
      "Gradient Descent(5/9): loss=4.249825551535528e+54, w=[3.85932827e+27 9.42317404e+59]\n",
      "Gradient Descent(6/9): loss=6.092793909502808e+64, w=[-2.21314203e+32 -1.35095959e+70]\n",
      "Gradient Descent(7/9): loss=8.734979159383746e+74, w=[1.26913280e+37 1.93681314e+80]\n",
      "Gradient Descent(8/9): loss=1.252296763162547e+85, w=[-7.27787966e+41 -2.77672651e+90]\n",
      "Gradient Descent(9/9): loss=1.7953645388411342e+95, w=[4.17352167e+046 3.98087455e+100]\n",
      "SGD(0/9): loss=358583626.6124617\n",
      "SGD(1/9): loss=25416825417788.723\n",
      "SGD(2/9): loss=2.1507553224731968e+18\n",
      "SGD(3/9): loss=2.1534279211986512e+23\n",
      "SGD(4/9): loss=6.114285149993397e+24\n",
      "SGD(5/9): loss=5.439732098789921e+28\n",
      "SGD(6/9): loss=2.7731420424781686e+33\n",
      "SGD(7/9): loss=6.410797553596092e+35\n",
      "SGD(8/9): loss=4.812413442863127e+40\n",
      "SGD(9/9): loss=4.821042632982024e+45\n"
     ]
    }
   ],
   "source": [
    "#loss1, w1 = least_squares(y, tX)\n",
    "#loss2, w2 = ridge_regression(y, tX, w)\n",
    "#loss3, w3 = log_reg(yp, tX, wp, max_iters, gamma)\n",
    "#loss4, w4 = reg_log_reg(yp, tX, wp, max_iters, gamma)\n",
    "#loss5, w5 = least_squares_GD(y, tX, w, max_iters, gamma)\n",
    "#loss6, w6 = least_squares_SGD(y, tX, w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
