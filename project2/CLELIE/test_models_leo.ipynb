{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'im_processing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-01bcfc026310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimg_preprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mLIDAR_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mim_postprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/EPFL/MA1a/Machine Learning/ML_proj.nosync/project2/CLELIE/im_postprocess.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#from model_example import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mim_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EPFL/MA1a/Machine Learning/ML_proj.nosync/project2/CLELIE/helpers_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_v2_behavior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mim_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'im_processing'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, ZeroPadding2D, Convolution2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from sklearn.metrics import f1_score\n",
    "from PIL import Image\n",
    "\n",
    "from constant_values import *\n",
    "from img_preprocessing import *\n",
    "from LIDAR_model import *\n",
    "from im_postprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 100/100 is being processed ... Shuffle data ...\n",
      "Image 100/100 is being processed ... Shuffle data ...\n"
     ]
    }
   ],
   "source": [
    "tr_imgs = data_augmentation(\"../Data/training/images/\")      #100 images --> 2400 images\n",
    "gt_imgs = data_augmentation(\"../Data/training/groundtruth/\") #100 images --> 2400 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract each images into patches (numpy arrays).\n",
    "img = extract_data(tr_imgs, TRAINING_SIZE)  #shape: ((400/16)^2 * TRAINING_SIZE, 16, 16, 3)\n",
    "gt = extract_labels(gt_imgs, TRAINING_SIZE) #shape: ((400/16)^2 * TRAINING_SIZE, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Test model simple\n",
    "\n",
    "# Create model\n",
    "# https://keras.io/models/sequential/\n",
    "#mod = Sequential()\n",
    "\n",
    "# Add a layer\n",
    "# https://keras.io/layers/about-keras-layers/\n",
    "# https://keras.io/activations/\n",
    "#mod.add(Conv2D(64, kernel_size=IMG_PATCH_SIZE, activation='relu',input_shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS)))\n",
    "#mod.add(Flatten())\n",
    "#mod.add(Dense(2, activation='softmax'))\n",
    "        \n",
    "        \n",
    "# https://keras.io/optimizers/\n",
    "# https://keras.io/losses/\n",
    "#mod.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy']) #f1 = 0.43\n",
    "#mod.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy']) #f1 = 0.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model_Lidar((16, 16, 3))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "4/4 [==============================] - 133s 33s/step - loss: 0.9083 - acc: 0.7188 - val_loss: 0.6783 - val_acc: 0.7729\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 122s 30s/step - loss: 1.0764 - acc: 0.7500 - val_loss: 0.6475 - val_acc: 0.7774\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 104s 26s/step - loss: 0.9155 - acc: 0.8281 - val_loss: 0.6688 - val_acc: 0.8049\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 116s 29s/step - loss: 0.8720 - acc: 0.8594 - val_loss: 0.6599 - val_acc: 0.7896\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 99s 25s/step - loss: 0.9682 - acc: 0.7969 - val_loss: 0.6282 - val_acc: 0.7988\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 103s 26s/step - loss: 1.1376 - acc: 0.7031 - val_loss: 0.6489 - val_acc: 0.8018\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 98s 25s/step - loss: 0.9928 - acc: 0.7812 - val_loss: 0.6722 - val_acc: 0.8049\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 99s 25s/step - loss: 0.9223 - acc: 0.8281 - val_loss: 0.6777 - val_acc: 0.7820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a393f9350>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_SIZE = 0.33 # To be studied\n",
    "\n",
    "# Step 0: Shuffle samples\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(img)\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(gt)\n",
    "\n",
    "# Step 1: Split into validation and training set     \n",
    "Xtrain, Xtest, gt_train, gt_test = train_test_split(img, gt, test_size=TEST_SIZE, random_state=1)\n",
    "\n",
    "# Step 2: Give weights to classes ?\n",
    "c_weight = {1: 3., \n",
    "            0: 1.}\n",
    "\n",
    "# Step 3: Generate Generators\n",
    "train_datagenerator = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "test_datagenerator  = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagenerator.flow(Xtrain, gt_train, batch_size=BATCH_SIZE)\n",
    "test_generator  = test_datagenerator.flow(Xtest, gt_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Step 4: Early stop\n",
    "early_stop_callback = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=0, mode='max', restore_best_weights=True)\n",
    "\n",
    "# Step 5: Training\n",
    "model.fit_generator(train_generator,\n",
    "            validation_data=test_generator,\n",
    "            steps_per_epoch=math.ceil(TRAINING_SIZE / BATCH_SIZE), #len(train_generator)/16,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            callbacks = [early_stop_callback],\n",
    "            class_weight=c_weight,\n",
    "            validation_steps=math.ceil(len(test_generator)/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_to_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-87561d3069e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAINING_SIZE\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction_with_groundtruth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_training_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"prediction_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction_with_overlay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EPFL/MA1a/Machine Learning/ML_proj.nosync/project2/CLELIE/predictions.py\u001b[0m in \u001b[0;36mget_prediction_with_groundtruth\u001b[0;34m(filename, image_idx, model)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mimg_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mcimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EPFL/MA1a/Machine Learning/ML_proj.nosync/project2/CLELIE/predictions.py\u001b[0m in \u001b[0;36mget_prediction\u001b[0;34m(img, model)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_PATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_PATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0moutput_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mimg_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_PATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_PATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg_prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label_to_img' is not defined"
     ]
    }
   ],
   "source": [
    "train_data_filename = \"../Data/training/images/\"\n",
    "\n",
    "prediction_training_dir = \"predictions_training_lidar_model_LEO/\"\n",
    "if not os.path.isdir(prediction_training_dir):\n",
    "    os.mkdir(prediction_training_dir)\n",
    "\n",
    "for i in range(1, TRAINING_SIZE+1):\n",
    "    pimg = get_prediction_with_groundtruth(train_data_filename, i, model)\n",
    "    Image.fromarray(pimg).save(prediction_training_dir + \"prediction_\" + str(i) + \".png\")\n",
    "    oimg = get_prediction_with_overlay(train_data_filename, i, model)\n",
    "    oimg.save(prediction_training_dir + \"overlay_\" + str(i) + \".png\")\n",
    "\n",
    "\n",
    "# serialize model to JSON\n",
    "OUTPUT_FILENAME = \"simple_model\"\n",
    "model_json = model.to_json()\n",
    "with open(OUTPUT_FILENAME + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(OUTPUT_FILENAME + \".h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "validation_data_prediction = mod.predict_classes(data_te)\n",
    "validation_label = []\n",
    "for e in label_te:\n",
    "    if (e[0] == 0):\n",
    "        validation_label.append(1)\n",
    "    else:\n",
    "        validation_label.append(0)\n",
    "        \n",
    "validation_label = np.array(validation_label)     \n",
    "print(\"F1 score = \"+str(f1_score(validation_data_prediction, validation_label, labels=['1'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
