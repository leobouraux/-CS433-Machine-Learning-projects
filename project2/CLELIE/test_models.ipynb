{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, ZeroPadding2D, Convolution2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "from constant_values import *\n",
    "from img_preprocessing import *\n",
    "from LIDAR_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../Data/training/images/satImage_001.png\n",
      "Loading ../Data/training/images/satImage_002.png\n",
      "Loading ../Data/training/images/satImage_003.png\n",
      "Loading ../Data/training/images/satImage_004.png\n",
      "Loading ../Data/training/images/satImage_005.png\n",
      "Loading ../Data/training/images/satImage_006.png\n",
      "Loading ../Data/training/images/satImage_007.png\n",
      "Loading ../Data/training/images/satImage_008.png\n",
      "Loading ../Data/training/images/satImage_009.png\n",
      "Loading ../Data/training/images/satImage_010.png\n",
      "Loading ../Data/training/images/satImage_011.png\n",
      "Loading ../Data/training/images/satImage_012.png\n",
      "Loading ../Data/training/images/satImage_013.png\n",
      "Loading ../Data/training/images/satImage_014.png\n",
      "Loading ../Data/training/images/satImage_015.png\n",
      "Loading ../Data/training/images/satImage_016.png\n",
      "Loading ../Data/training/images/satImage_017.png\n",
      "Loading ../Data/training/images/satImage_018.png\n",
      "Loading ../Data/training/images/satImage_019.png\n",
      "Loading ../Data/training/images/satImage_020.png\n",
      "Loading ../Data/training/images/satImage_021.png\n",
      "Loading ../Data/training/images/satImage_022.png\n",
      "Loading ../Data/training/images/satImage_023.png\n",
      "Loading ../Data/training/images/satImage_024.png\n",
      "Loading ../Data/training/images/satImage_025.png\n",
      "Loading ../Data/training/images/satImage_026.png\n",
      "Loading ../Data/training/images/satImage_027.png\n",
      "Loading ../Data/training/images/satImage_028.png\n",
      "Loading ../Data/training/images/satImage_029.png\n",
      "Loading ../Data/training/images/satImage_030.png\n",
      "Loading ../Data/training/images/satImage_031.png\n",
      "Loading ../Data/training/images/satImage_032.png\n",
      "Loading ../Data/training/images/satImage_033.png\n",
      "Loading ../Data/training/images/satImage_034.png\n",
      "Loading ../Data/training/images/satImage_035.png\n",
      "Loading ../Data/training/images/satImage_036.png\n",
      "Loading ../Data/training/images/satImage_037.png\n",
      "Loading ../Data/training/images/satImage_038.png\n",
      "Loading ../Data/training/images/satImage_039.png\n",
      "Loading ../Data/training/images/satImage_040.png\n",
      "Loading ../Data/training/images/satImage_041.png\n",
      "Loading ../Data/training/images/satImage_042.png\n",
      "Loading ../Data/training/images/satImage_043.png\n",
      "Loading ../Data/training/images/satImage_044.png\n",
      "Loading ../Data/training/images/satImage_045.png\n",
      "Loading ../Data/training/images/satImage_046.png\n",
      "Loading ../Data/training/images/satImage_047.png\n",
      "Loading ../Data/training/images/satImage_048.png\n",
      "Loading ../Data/training/images/satImage_049.png\n",
      "Loading ../Data/training/images/satImage_050.png\n",
      "Loading ../Data/training/groundtruth/satImage_001.png\n",
      "Loading ../Data/training/groundtruth/satImage_002.png\n",
      "Loading ../Data/training/groundtruth/satImage_003.png\n",
      "Loading ../Data/training/groundtruth/satImage_004.png\n",
      "Loading ../Data/training/groundtruth/satImage_005.png\n",
      "Loading ../Data/training/groundtruth/satImage_006.png\n",
      "Loading ../Data/training/groundtruth/satImage_007.png\n",
      "Loading ../Data/training/groundtruth/satImage_008.png\n",
      "Loading ../Data/training/groundtruth/satImage_009.png\n",
      "Loading ../Data/training/groundtruth/satImage_010.png\n",
      "Loading ../Data/training/groundtruth/satImage_011.png\n",
      "Loading ../Data/training/groundtruth/satImage_012.png\n",
      "Loading ../Data/training/groundtruth/satImage_013.png\n",
      "Loading ../Data/training/groundtruth/satImage_014.png\n",
      "Loading ../Data/training/groundtruth/satImage_015.png\n",
      "Loading ../Data/training/groundtruth/satImage_016.png\n",
      "Loading ../Data/training/groundtruth/satImage_017.png\n",
      "Loading ../Data/training/groundtruth/satImage_018.png\n",
      "Loading ../Data/training/groundtruth/satImage_019.png\n",
      "Loading ../Data/training/groundtruth/satImage_020.png\n",
      "Loading ../Data/training/groundtruth/satImage_021.png\n",
      "Loading ../Data/training/groundtruth/satImage_022.png\n",
      "Loading ../Data/training/groundtruth/satImage_023.png\n",
      "Loading ../Data/training/groundtruth/satImage_024.png\n",
      "Loading ../Data/training/groundtruth/satImage_025.png\n",
      "Loading ../Data/training/groundtruth/satImage_026.png\n",
      "Loading ../Data/training/groundtruth/satImage_027.png\n",
      "Loading ../Data/training/groundtruth/satImage_028.png\n",
      "Loading ../Data/training/groundtruth/satImage_029.png\n",
      "Loading ../Data/training/groundtruth/satImage_030.png\n",
      "Loading ../Data/training/groundtruth/satImage_031.png\n",
      "Loading ../Data/training/groundtruth/satImage_032.png\n",
      "Loading ../Data/training/groundtruth/satImage_033.png\n",
      "Loading ../Data/training/groundtruth/satImage_034.png\n",
      "Loading ../Data/training/groundtruth/satImage_035.png\n",
      "Loading ../Data/training/groundtruth/satImage_036.png\n",
      "Loading ../Data/training/groundtruth/satImage_037.png\n",
      "Loading ../Data/training/groundtruth/satImage_038.png\n",
      "Loading ../Data/training/groundtruth/satImage_039.png\n",
      "Loading ../Data/training/groundtruth/satImage_040.png\n",
      "Loading ../Data/training/groundtruth/satImage_041.png\n",
      "Loading ../Data/training/groundtruth/satImage_042.png\n",
      "Loading ../Data/training/groundtruth/satImage_043.png\n",
      "Loading ../Data/training/groundtruth/satImage_044.png\n",
      "Loading ../Data/training/groundtruth/satImage_045.png\n",
      "Loading ../Data/training/groundtruth/satImage_046.png\n",
      "Loading ../Data/training/groundtruth/satImage_047.png\n",
      "Loading ../Data/training/groundtruth/satImage_048.png\n",
      "Loading ../Data/training/groundtruth/satImage_049.png\n",
      "Loading ../Data/training/groundtruth/satImage_050.png\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../Data/training/'\n",
    "img_dir = data_dir + 'images/'\n",
    "gt_dir = data_dir + 'groundtruth/'\n",
    "\n",
    "# Extract it into numpy arrays.\n",
    "img = extract_data(img_dir, TRAINING_SIZE)\n",
    "gt = extract_labels(gt_dir, TRAINING_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Test model simple\n",
    "\n",
    "# Create model\n",
    "# https://keras.io/models/sequential/\n",
    "#mod = Sequential()\n",
    "\n",
    "# Add a layer\n",
    "# https://keras.io/layers/about-keras-layers/\n",
    "# https://keras.io/activations/\n",
    "#mod.add(Conv2D(64, kernel_size=IMG_PATCH_SIZE, activation='relu',input_shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS)))\n",
    "#mod.add(Flatten())\n",
    "#mod.add(Dense(2, activation='softmax'))\n",
    "        \n",
    "        \n",
    "# https://keras.io/optimizers/\n",
    "# https://keras.io/losses/\n",
    "#mod.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy']) #f1 = 0.43\n",
    "#mod.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy']) #f1 = 0.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_Lidar((16, 16, 3))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 22s 5s/step - loss: 1.0609 - accuracy: 0.3438 - val_loss: 0.7243 - val_accuracy: 0.2287\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clelie/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 19s 5s/step - loss: 1.0273 - accuracy: 0.6094 - val_loss: 0.6433 - val_accuracy: 0.7271\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.0548 - accuracy: 0.5156 - val_loss: 0.7021 - val_accuracy: 0.2287\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.0926 - accuracy: 0.2344 - val_loss: 0.7105 - val_accuracy: 0.2759\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.1264 - accuracy: 0.3750 - val_loss: 0.7120 - val_accuracy: 0.2668\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 1.0432 - accuracy: 0.2969 - val_loss: 0.7310 - val_accuracy: 0.2378\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.9275 - accuracy: 0.3594 - val_loss: 0.6618 - val_accuracy: 0.7576\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 1.0489 - accuracy: 0.7500 - val_loss: 0.6641 - val_accuracy: 0.7454\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.1077 - accuracy: 0.4062 - val_loss: 0.7645 - val_accuracy: 0.2500\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 1.0107 - accuracy: 0.2031 - val_loss: 0.6980 - val_accuracy: 0.3125\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.0405 - accuracy: 0.6094 - val_loss: 0.6684 - val_accuracy: 0.7683\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.1264 - accuracy: 0.5469 - val_loss: 0.6984 - val_accuracy: 0.2729\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 1.1187 - accuracy: 0.4219 - val_loss: 0.7283 - val_accuracy: 0.2470\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 1.0109 - accuracy: 0.2344 - val_loss: 0.7195 - val_accuracy: 0.2439\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.1276 - accuracy: 0.4844 - val_loss: 0.7025 - val_accuracy: 0.2835\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 1.0297 - accuracy: 0.2812 - val_loss: 0.7292 - val_accuracy: 0.2635\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 1.1154 - accuracy: 0.3438 - val_loss: 0.7609 - val_accuracy: 0.2576\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.9962 - accuracy: 0.3594 - val_loss: 0.6697 - val_accuracy: 0.7043\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.9808 - accuracy: 0.6094 - val_loss: 0.6213 - val_accuracy: 0.7149\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.2914 - accuracy: 0.5469 - val_loss: 0.7509 - val_accuracy: 0.2424\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.9744 - accuracy: 0.2344 - val_loss: 0.6977 - val_accuracy: 0.2668\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.8708 - accuracy: 0.6562 - val_loss: 0.6107 - val_accuracy: 0.7241\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.1244 - accuracy: 0.7031 - val_loss: 0.6448 - val_accuracy: 0.7713\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 1.1849 - accuracy: 0.3438 - val_loss: 0.7845 - val_accuracy: 0.2470\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.9396 - accuracy: 0.4844 - val_loss: 0.5999 - val_accuracy: 0.7256\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 22s 5s/step - loss: 0.9184 - accuracy: 0.7500 - val_loss: 0.6167 - val_accuracy: 0.7652\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 21s 5s/step - loss: 1.0356 - accuracy: 0.6406 - val_loss: 1.1609 - val_accuracy: 0.2652\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 21s 5s/step - loss: 1.1757 - accuracy: 0.4062 - val_loss: 0.6133 - val_accuracy: 0.7637\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 20s 5s/step - loss: 1.1584 - accuracy: 0.4219 - val_loss: 0.7889 - val_accuracy: 0.2424\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 1.0137 - accuracy: 0.4062 - val_loss: 0.6497 - val_accuracy: 0.7820\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.2079 - accuracy: 0.5156 - val_loss: 0.8702 - val_accuracy: 0.2485\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.0791 - accuracy: 0.2188 - val_loss: 0.6626 - val_accuracy: 0.7011\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 1.0673 - accuracy: 0.4219 - val_loss: 0.7482 - val_accuracy: 0.2500\n",
      "Epoch 34/100\n",
      "3/4 [=====================>........] - ETA: 1s - loss: 1.2006 - accuracy: 0.4583"
     ]
    }
   ],
   "source": [
    "TEST_SIZE = 0.33 # To be studied\n",
    "\n",
    "# Step 0: Shuffle samples\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(img)\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(gt)\n",
    "\n",
    "# Step 1: Split into validation and training set     \n",
    "Xtrain, Xtest, gt_train, gt_test = train_test_split(img, gt, test_size=TEST_SIZE, random_state=1)\n",
    "\n",
    "# Step 2: Give weights to classes ?\n",
    "c_weight = {1: 3., \n",
    "            0: 1.}\n",
    "\n",
    "# Step 3: Generate Generators\n",
    "train_datagenerator = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "test_datagenerator  = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagenerator.flow(Xtrain, gt_train, batch_size=BATCH_SIZE)\n",
    "test_generator  = test_datagenerator.flow(Xtest, gt_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Step 4: Early stop\n",
    "early_stop_callback = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=0, mode='max', restore_best_weights=True)\n",
    "\n",
    "# Step 5: Training\n",
    "model.fit_generator(train_generator,\n",
    "            validation_data=test_generator,\n",
    "            steps_per_epoch=math.ceil(TRAINING_SIZE / BATCH_SIZE), #len(train_generator)/16,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            callbacks = [early_stop_callback],\n",
    "            class_weight=c_weight,\n",
    "            validation_steps=math.ceil(len(test_generator)/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_training_dir = \"predictions_training_vgg_model/\"\n",
    "if not os.path.isdir(prediction_training_dir):\n",
    "    os.mkdir(prediction_training_dir)\n",
    "\n",
    "for i in range(1, TRAINING_SIZE+1):\n",
    "    pimg = get_prediction_with_groundtruth(train_data_filename, i, mod_vgg)\n",
    "    Image.fromarray(pimg).save(prediction_training_dir + \"prediction_\" + str(i) + \".png\")\n",
    "    oimg = get_prediction_with_overlay(train_data_filename, i, mod_vgg)\n",
    "    oimg.save(prediction_training_dir + \"overlay_\" + str(i) + \".png\")\n",
    "\n",
    "\n",
    "# serialize model to JSON\n",
    "OUTPUT_FILENAME = \"simple_model\"\n",
    "model_json = mod.to_json()\n",
    "with open(OUTPUT_FILENAME + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "mod.save_weights(OUTPUT_FILENAME + \".h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "validation_data_prediction = mod.predict_classes(data_te)\n",
    "validation_label = []\n",
    "for e in label_te:\n",
    "    if (e[0] == 0):\n",
    "        validation_label.append(1)\n",
    "    else:\n",
    "        validation_label.append(0)\n",
    "        \n",
    "validation_label = np.array(validation_label)     \n",
    "print(\"F1 score = \"+str(f1_score(validation_data_prediction, validation_label, labels=['1'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
