{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, ZeroPadding2D, Convolution2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "from predictions import *\n",
    "from im_postprocess import*\n",
    "from im_processing import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHANNELS    = 3  # RGB images\n",
    "PIXEL_DEPTH     = 255\n",
    "NUM_LABELS      = 2\n",
    "TRAINING_SIZE   = 50\n",
    "VALIDATION_SIZE = 5  # Size of the validation set.\n",
    "SEED            = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE      = 16  # 64\n",
    "NUM_EPOCHS      = 100\n",
    "RESTORE_MODEL   = False  # If True, restore existing model instead of training a new one\n",
    "RECORDING_STEP  = 0\n",
    "FG_THRESH       = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "IMG_PATCH_SIZE  = 16 # IMG_PATCH_SIZE should be a multiple of 4, image size should be an integer multiple of this number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../Datasets/training/images/satImage_001.png\n",
      "Loading ../Datasets/training/images/satImage_002.png\n",
      "Loading ../Datasets/training/images/satImage_003.png\n",
      "Loading ../Datasets/training/images/satImage_004.png\n",
      "Loading ../Datasets/training/images/satImage_005.png\n",
      "Loading ../Datasets/training/images/satImage_006.png\n",
      "Loading ../Datasets/training/images/satImage_007.png\n",
      "Loading ../Datasets/training/images/satImage_008.png\n",
      "Loading ../Datasets/training/images/satImage_009.png\n",
      "Loading ../Datasets/training/images/satImage_010.png\n",
      "Loading ../Datasets/training/images/satImage_011.png\n",
      "Loading ../Datasets/training/images/satImage_012.png\n",
      "Loading ../Datasets/training/images/satImage_013.png\n",
      "Loading ../Datasets/training/images/satImage_014.png\n",
      "Loading ../Datasets/training/images/satImage_015.png\n",
      "Loading ../Datasets/training/images/satImage_016.png\n",
      "Loading ../Datasets/training/images/satImage_017.png\n",
      "Loading ../Datasets/training/images/satImage_018.png\n",
      "Loading ../Datasets/training/images/satImage_019.png\n",
      "Loading ../Datasets/training/images/satImage_020.png\n",
      "Loading ../Datasets/training/images/satImage_021.png\n",
      "Loading ../Datasets/training/images/satImage_022.png\n",
      "Loading ../Datasets/training/images/satImage_023.png\n",
      "Loading ../Datasets/training/images/satImage_024.png\n",
      "Loading ../Datasets/training/images/satImage_025.png\n",
      "Loading ../Datasets/training/images/satImage_026.png\n",
      "Loading ../Datasets/training/images/satImage_027.png\n",
      "Loading ../Datasets/training/images/satImage_028.png\n",
      "Loading ../Datasets/training/images/satImage_029.png\n",
      "Loading ../Datasets/training/images/satImage_030.png\n",
      "Loading ../Datasets/training/images/satImage_031.png\n",
      "Loading ../Datasets/training/images/satImage_032.png\n",
      "Loading ../Datasets/training/images/satImage_033.png\n",
      "Loading ../Datasets/training/images/satImage_034.png\n",
      "Loading ../Datasets/training/images/satImage_035.png\n",
      "Loading ../Datasets/training/images/satImage_036.png\n",
      "Loading ../Datasets/training/images/satImage_037.png\n",
      "Loading ../Datasets/training/images/satImage_038.png\n",
      "Loading ../Datasets/training/images/satImage_039.png\n",
      "Loading ../Datasets/training/images/satImage_040.png\n",
      "Loading ../Datasets/training/images/satImage_041.png\n",
      "Loading ../Datasets/training/images/satImage_042.png\n",
      "Loading ../Datasets/training/images/satImage_043.png\n",
      "Loading ../Datasets/training/images/satImage_044.png\n",
      "Loading ../Datasets/training/images/satImage_045.png\n",
      "Loading ../Datasets/training/images/satImage_046.png\n",
      "Loading ../Datasets/training/images/satImage_047.png\n",
      "Loading ../Datasets/training/images/satImage_048.png\n",
      "Loading ../Datasets/training/images/satImage_049.png\n",
      "Loading ../Datasets/training/images/satImage_050.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_001.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_002.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_003.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_004.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_005.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_006.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_007.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_008.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_009.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_010.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_011.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_012.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_013.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_014.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_015.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_016.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_017.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_018.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_019.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_020.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_021.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_022.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_023.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_024.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_025.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_026.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_027.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_028.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_029.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_030.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_031.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_032.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_033.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_034.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_035.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_036.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_037.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_038.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_039.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_040.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_041.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_042.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_043.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_044.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_045.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_046.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_047.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_048.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_049.png\n",
      "Loading ../Datasets/training/groundtruth/satImage_050.png\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../Datasets/training/'\n",
    "train_data_filename = data_dir + 'images/'\n",
    "train_labels_filename = data_dir + 'groundtruth/'\n",
    "\n",
    "# Extract it into numpy arrays.\n",
    "train_data = extract_data(train_data_filename, TRAINING_SIZE)\n",
    "train_labels = extract_labels(train_labels_filename, TRAINING_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test model simple\n",
    "\n",
    "# Create model\n",
    "# https://keras.io/models/sequential/\n",
    "mod = Sequential()\n",
    "\n",
    "# Add a layer\n",
    "# https://keras.io/layers/about-keras-layers/\n",
    "# https://keras.io/activations/\n",
    "mod.add(Conv2D(64, kernel_size=IMG_PATCH_SIZE, activation='relu',input_shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS)))\n",
    "mod.add(Flatten())\n",
    "mod.add(Dense(2, activation='softmax'))\n",
    "        \n",
    "        \n",
    "# https://keras.io/optimizers/\n",
    "# https://keras.io/losses/\n",
    "mod.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy']) #f1 = 0.43\n",
    "#mod.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy']) #f1 = 0.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leobouraux/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/leobouraux/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "/Users/leobouraux/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/leobouraux/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "  if sys.path[0] == '':\n",
      "/Users/leobouraux/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "/Users/leobouraux/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "/Users/leobouraux/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leobouraux/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "/Users/leobouraux/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "/Users/leobouraux/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "/Users/leobouraux/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "/Users/leobouraux/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "/Users/leobouraux/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"
     ]
    }
   ],
   "source": [
    "# VGG qui marche pas\n",
    "mod_vgg = Sequential()\n",
    "mod_vgg.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "mod_vgg.add(Convolution2D(64, 3, 3, activation=\"relu\"))\n",
    "mod_vgg.add(ZeroPadding2D((1,1)))\n",
    "mod_vgg.add(Convolution2D(64, 3, 3, activation=\"relu\"))\n",
    "mod_vgg.add(MaxPooling2D((2,2), strides=(2,2), padding=\"same\"))\n",
    "\n",
    "mod_vgg.add(ZeroPadding2D((1,1)))\n",
    "mod_vgg.add(Convolution2D(128, 3, 3, activation=\"relu\"))\n",
    "mod_vgg.add(ZeroPadding2D((1,1)))\n",
    "mod_vgg.add(Convolution2D(128, 3, 3, activation=\"relu\"))\n",
    "mod_vgg.add(MaxPooling2D((2,2), strides=(2,2), padding='same')) ###This line gives error\n",
    "\n",
    "mod_vgg.add(ZeroPadding2D((1,1)))\n",
    "mod_vgg.add(Convolution2D(256, 3, 3, activation=\"relu\"))\n",
    "mod_vgg.add(ZeroPadding2D((1,1)))\n",
    "mod_vgg.add(Convolution2D(256, 3, 3, activation=\"relu\"))\n",
    "mod_vgg.add(ZeroPadding2D((1,1)))\n",
    "mod_vgg.add(Convolution2D(256, 3, 3, activation=\"relu\"))\n",
    "mod_vgg.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "mod_vgg.add(ZeroPadding2D((1,1)))\n",
    "mod_vgg.add(Convolution2D(512, 3, 3, activation=\"relu\"))\n",
    "mod_vgg.add(ZeroPadding2D((1,1)))\n",
    "mod_vgg.add(Convolution2D(512, 3, 3, activation=\"relu\"))\n",
    "mod_vgg.add(ZeroPadding2D((1,1)))\n",
    "mod_vgg.add(Convolution2D(512, 3, 3, activation=\"relu\"))\n",
    "mod_vgg.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "mod_vgg.add(ZeroPadding2D((1,1)))\n",
    "mod_vgg.add(Convolution2D(512, 3, 3, activation=\"relu\"))\n",
    "mod_vgg.add(ZeroPadding2D((1,1)))\n",
    "mod_vgg.add(Convolution2D(512, 3, 3, activation=\"relu\"))\n",
    "mod_vgg.add(ZeroPadding2D((1,1)))\n",
    "mod_vgg.add(Convolution2D(512, 3, 3, activation=\"relu\"))\n",
    "mod_vgg.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "mod_vgg.add(Flatten())\n",
    "mod_vgg.add(Dense(4096, activation=\"relu\"))\n",
    "mod_vgg.add(Dropout(0.5))\n",
    "mod_vgg.add(Dense(4096, activation=\"relu\"))\n",
    "mod_vgg.add(Dropout(0.5))\n",
    "mod_vgg.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "\n",
    "#adam_optimizer = Adam(lr=0.001)\n",
    "mod_vgg.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leobouraux/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected zero_padding2d_1_input to have shape (3, 224, 224) but got array with shape (16, 16, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c9926e9288af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearly_stop_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             validation_steps=math.ceil(len(test_generator)/BATCH_SIZE))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected zero_padding2d_1_input to have shape (3, 224, 224) but got array with shape (16, 16, 3)"
     ]
    }
   ],
   "source": [
    "TEST_SIZE = 0.33 # To be studied\n",
    "\n",
    "# Step 0: Shuffle samples\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(train_data)\n",
    "# resetting the seed allows for an identical shuffling between y and x\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(train_labels)\n",
    "\n",
    "# Step 1: Split into validation and training set     \n",
    "data_tr, data_te, label_tr, label_te = train_test_split(train_data, train_labels, test_size=TEST_SIZE, random_state=1)\n",
    "\n",
    "# Step 2: Give weights to classes ?\n",
    "c_weight = {1: 3., \n",
    "            0: 1.}\n",
    "\n",
    "# Step 3: Greate Generators\n",
    "datagen_tr = ImageDataGenerator()\n",
    "datagen_te = ImageDataGenerator()\n",
    "\n",
    "train_generator = datagen_tr.flow(data_tr, label_tr, batch_size=BATCH_SIZE)\n",
    "test_generator  = datagen_te.flow(data_te, label_te, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Step 4: Early stop\n",
    "early_stop_callback = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=0, mode='max', restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "# Step 5: Training\n",
    "mod_vgg.fit_generator(train_generator,\n",
    "            validation_data=test_generator,\n",
    "            steps_per_epoch=math.ceil(TRAINING_SIZE / BATCH_SIZE), #len(train_generator)/16,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            callbacks = [early_stop_callback],\n",
    "            class_weight=c_weight,\n",
    "            validation_steps=math.ceil(len(test_generator)/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_training_dir = \"predictions_training_vgg_model/\"\n",
    "if not os.path.isdir(prediction_training_dir):\n",
    "    os.mkdir(prediction_training_dir)\n",
    "\n",
    "for i in range(1, TRAINING_SIZE+1):\n",
    "    pimg = get_prediction_with_groundtruth(train_data_filename, i, mod_vgg)\n",
    "    Image.fromarray(pimg).save(prediction_training_dir + \"prediction_\" + str(i) + \".png\")\n",
    "    oimg = get_prediction_with_overlay(train_data_filename, i, mod_vgg)\n",
    "    oimg.save(prediction_training_dir + \"overlay_\" + str(i) + \".png\")\n",
    "\n",
    "\n",
    "# serialize model to JSON\n",
    "OUTPUT_FILENAME = \"simple_model\"\n",
    "model_json = mod.to_json()\n",
    "with open(OUTPUT_FILENAME + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "mod.save_weights(OUTPUT_FILENAME + \".h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "validation_data_prediction = mod.predict_classes(data_te)\n",
    "validation_label = []\n",
    "for e in label_te:\n",
    "    if (e[0] == 0):\n",
    "        validation_label.append(1)\n",
    "    else:\n",
    "        validation_label.append(0)\n",
    "        \n",
    "validation_label = np.array(validation_label)     \n",
    "print(\"F1 score = \"+str(f1_score(validation_data_prediction, validation_label, labels=['1'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
