{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 50\n",
    "IMG_PATCH_SIZE = 16 # image size should be an integer multiple of this number!\n",
    "NUM_CHANNELS = 3 # RGB images\n",
    "FOREGROUND_THRESHOLD = 0.5  # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "TRAINING_SIZE = 100\n",
    "WINDOW_SIZE = 16\n",
    "\n",
    "seed = np.random.randint(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 100/100 is being processed ... Shuffle data ...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5110527cc8d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtr_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data/training/images/\"\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m#100 images --> 2400 images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mgt_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data/training/groundtruth/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#100 images --> 2400 images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5110527cc8d1>\u001b[0m in \u001b[0;36mdata_augmentation\u001b[0;34m(directory_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mrand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mtr_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data/training/images/\"\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m#100 images --> 2400 images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "def data_augmentation(directory_name): \n",
    "    datagen = ImageDataGenerator()\n",
    "    filenames = os.listdir(directory_name)\n",
    "    \n",
    "    #create 24 rotated images for one image\n",
    "    angls = np.arange(0, 360, 15)\n",
    "    zooms = np.array([1., 0.85, 0.8, 0.75, 0.8, 0.85,\n",
    "                      1., 0.85, 0.8, 0.75, 0.8, 0.85,\n",
    "                      1., 0.85, 0.8, 0.75, 0.8, 0.85,\n",
    "                      1., 0.85, 0.8, 0.75, 0.8, 0.85])\n",
    "    imgs = []\n",
    "    \n",
    "    for i, fileNb in enumerate(filenames):\n",
    "        img=mpimg.imread(directory_name+fileNb)\n",
    "        imgr = img_to_array(img)\n",
    "        for j, angle in enumerate(angls):\n",
    "            zoom = zooms[j]\n",
    "            img2 = datagen.apply_transform(x=imgr, transform_parameters={'theta':angle, 'zx':zoom, 'zy':zoom})\n",
    "            imgs.append(img2)\n",
    "\n",
    "        sys.stdout.write(\"\\rImage {}/{} is being processed\".format(i+1,len(filenames)))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    print(' ... Shuffle data ...')\n",
    "    imgs1 = np.asarray(imgs)\n",
    "    np.random.seed(seed)\n",
    "    rand = np.random.randint(imgs1.shape[0], size=imgs1.shape[0])\n",
    "    return imgs1[rand, :, :, :]\n",
    "\n",
    "tr_imgs = data_augmentation(\"../Data/training/images/\")      #100 images --> 2400 images\n",
    "gt_imgs = data_augmentation(\"../Data/training/groundtruth/\") #100 images --> 2400 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "\n",
    "# add model layers\n",
    "model.add(Conv2D(16, kernel_size=IMG_PATCH_SIZE, activation='relu',\n",
    "                      input_shape=(IMG_PATCH_SIZE, IMG_PATCH_SIZE, NUM_CHANNELS)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Assign a label to a patch v\n",
    "def value_to_class(v):\n",
    "    df = np.sum(v)\n",
    "    if df > FOREGROUND_THRESHOLD:\n",
    "        return [0, 1]\n",
    "    else:\n",
    "        return [1, 0]\n",
    "\n",
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "\n",
    "# Extract label images\n",
    "def extract_labels(gt_imgs):\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"            \n",
    "    imgs = gt_imgs[:TRAINING_SIZE, :, :, :]\n",
    "\n",
    "    num_images = len(imgs)\n",
    "    gt_patches = [img_crop(gt_imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE) for i in range(num_images)]\n",
    "    data = np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "    labels = np.asarray([value_to_class(np.mean(data[i])) for i in range(len(data))])\n",
    "\n",
    "    # Convert to dense 1-hot representation.\n",
    "    return labels.astype(np.float32)\n",
    "\n",
    "    \n",
    "def create_patches(im):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    for i in range(0, imgheight, IMG_PATCH_SIZE):\n",
    "        for j in range(0, imgwidth, IMG_PATCH_SIZE):\n",
    "            im_patch = im[j:j+IMG_PATCH_SIZE, i:i+IMG_PATCH_SIZE, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "\n",
    "def extract_data(tr_imgs):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "    \"\"\"#todo\n",
    "    \n",
    "    imgs = tr_imgs[:TRAINING_SIZE, :, :, :]\n",
    "\n",
    "    IMG_WIDTH = imgs[0].shape[0]\n",
    "    IMG_HEIGHT = imgs[0].shape[1]\n",
    "    N_PATCHES_PER_IMAGE = (IMG_WIDTH/IMG_PATCH_SIZE)*(IMG_HEIGHT/IMG_PATCH_SIZE)\n",
    "\n",
    "    img_patches = [create_patches(imgs[i]) for i in range(TRAINING_SIZE)] #list of images (=list windows (=list pixels))\n",
    "    \n",
    "    data = [img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))] # j in range number of patch per image\n",
    "\n",
    "    return np.asarray(data)\n",
    "\n",
    "\n",
    "def load_data(tr_imgs, gt_imgs):\n",
    "        # Extract it into numpy arrays.\n",
    "        train_data = extract_data(tr_imgs) #shape: ((400/16)^2 * 100 = 62500, 16, 16, 3)\n",
    "        train_labels = extract_labels(gt_imgs) #shape: (62500, 2)\n",
    "        return train_data, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = load_data(tr_imgs, gt_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=100, validation_split=0.1):\n",
    "\n",
    "    # Step 0: Shuffle samples\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(train_data)\n",
    "    # resetting the seed allows for an identical shuffling between y and x\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(train_labels)\n",
    "\n",
    "    # Step 1: Split into validation and training set     \n",
    "    split_index = int(len(train_data) * (1 - validation_split))\n",
    "    train_data_split      = train_data[0:split_index]\n",
    "    validation_data_split = train_data[split_index:]\n",
    "    train_label_split     = train_labels[0:split_index]\n",
    "    validation_label_split= train_labels[split_index:]\n",
    "\n",
    "    # Step 2: Give weights to classes\n",
    "    c_weight = {1: 3., \n",
    "                0: 1.}\n",
    "\n",
    "    # Step 3: Greate Generators\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        #rotation_range=180,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)\n",
    "\n",
    "    validation_datagen = ImageDataGenerator()\n",
    "        #rotation_range=180,\n",
    "        #horizontal_flip=True,\n",
    "        #vertical_flip=True)\n",
    "\n",
    "    train_generator = train_datagen.flow(train_data_split, train_label_split, batch_size=32)\n",
    "    validation_generator = validation_datagen.flow(validation_data_split, validation_label_split, batch_size=32)\n",
    "\n",
    "\n",
    "    # Step 4: Early stop\n",
    "    early_stop_callback = EarlyStopping(monitor='val_acc', min_delta=0, patience=25, verbose=0, \n",
    "                                        mode='max', restore_best_weights=True)\n",
    "\n",
    "    # Finally, train the model !\n",
    "    # Training\n",
    "    model.fit_generator(train_generator,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=len(validation_data_split)/16,\n",
    "                        steps_per_epoch=len(train_data_split)/32,\n",
    "                        callbacks = [early_stop_callback],\n",
    "                        class_weight=c_weight)\n",
    "\n",
    "# Train model\n",
    "train(epochs=30, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
